{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "class CandidateGenerator(metaclass=ABCMeta):\n",
    "    def __init__(self, entities):\n",
    "        self.entities = entities\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(self, mentions, entities):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_candidates(self, mentions, k):\n",
    "        pass\n",
    "\n",
    "class Tokenizer(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def tokenize(self, text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['こんにちは', '宇宙']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "class MeCabTokenizer(Tokenizer):\n",
    "    def __init__(self, mecab):\n",
    "        self.mecab = mecab\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        tokens = self.mecab.parse(text).split()\n",
    "        return tokens\n",
    "mecab = MeCab.Tagger('-Owakati')\n",
    "tokenizer = MeCabTokenizer(mecab)\n",
    "tokenizer.tokenize(\"こんにちは宇宙\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "class BM25Generator(CandidateGenerator):\n",
    "    def __init__(self, entities, tokenizer):\n",
    "        \"\"\"\n",
    "        arg:\n",
    "            entities: List[[entity, mention]]\n",
    "            tokenizer: tokenizer\n",
    "        \"\"\"\n",
    "        super().__init__(entities)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.entities = [[e[0], self.tokenizer.tokenize(e[1])] for e in self.entities]\n",
    "        print(self.entities[:20])\n",
    "        self.bm25 = BM25Okapi([e[1] for e in self.entities])\n",
    "        \n",
    "    def train(self, mentions, entities):\n",
    "        pass\n",
    "    \n",
    "    def generate_candidates(self, mentions, k):\n",
    "        mentions = [self.tokenizer.tokenize(m) for m in mentions]\n",
    "        candidates = [self.bm25.get_top_n(m, self.entities, n=k) for m in mentions]\n",
    "        candidates = [[t[0] for t in tt] for tt in candidates]\n",
    "        return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "entities = []\n",
    "with open(\"/data1/ujiie/wiki_resource/alias_table.tsv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        if line[0] == \"id\":\n",
    "            continue\n",
    "        if len(line) != 2:\n",
    "            print(line)\n",
    "        entities.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['17432', ['記号']], ['6932', ['ラテン語']], ['90949', ['合', '字']], ['1848349', ['Trebuchet', 'MS']], ['16771', ['Z']], ['13663', ['ラテン', '文字']], ['18665', ['アルファベット']], ['2860395', ['ゲール', '文字']], ['67756', ['欧米']], ['371198', ['無声', '歯茎', '側面', '摩擦音']], ['558367', ['発音', '記号']], ['69', ['プログラミング', '言語']], ['1022', ['C']], ['34108', ['演算', '子']], ['3558', ['PHP']], ['613697', ['参照', '渡し']], ['1487', ['BASIC']], ['225994', ['文字', '列']], ['2454', ['マイクロソフト']], ['12099', ['十', '六', '進', '表記']]]\n"
     ]
    }
   ],
   "source": [
    "generator = BM25Generator(entities, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['122253',\n",
       "  '87504',\n",
       "  '155355',\n",
       "  '13663',\n",
       "  '549564',\n",
       "  '206006',\n",
       "  '9299',\n",
       "  '92256',\n",
       "  '6932',\n",
       "  '1011069'],\n",
       " ['61543',\n",
       "  '982166',\n",
       "  '1955411',\n",
       "  '647688',\n",
       "  '446530',\n",
       "  '3792760',\n",
       "  '432680',\n",
       "  '3813554',\n",
       "  '470790',\n",
       "  '1877939'],\n",
       " ['1860426',\n",
       "  '1955411',\n",
       "  '2114104',\n",
       "  '647688',\n",
       "  '2354056',\n",
       "  '446530',\n",
       "  '3792760',\n",
       "  '432680',\n",
       "  '3813554',\n",
       "  '470790']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate_candidates([\"ラテン\", \"オカピ\", \"Okapi\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
